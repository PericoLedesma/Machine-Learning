# Machine Learning


# Projects

Models evaluation for Handwritten Digits Recognition

## Description

Machine learning (ML) is about algorithms which are fed with (large quantities of) real-world data, and which return a compressed model of the data. An example is a spoken language model: the input data are speech recordings, from which ML methods build a model of spoken English -- useful, for instance, in automated speech recognition systems. There exists a large number of formalisms in which such models can be formulated and implemented, and an even larger diversity of learning algorithms to estimate such models from data. However, there is only a relatively small number of fundamental challenges which are common to all of these formalisms and algorithms. This lecture introduces such fundamental concepts and a choice of standard model formalisms (decision trees, linear classifiers and regressors, K-means clustering, self-organizing feature maps, sampling / energy based distribution modeling, hidden Markov models and graphical models, feedforward and recurrent neural networks). 
There will be a practical where students will implement their own machine learning system and they will write a report about this system and the obtained results. Furthermore, there will be a written final exam at the end of the course.

## Learning outcomes

1) understand and appreciate universal challenges that arise in (almost) every machine learning (ML) project: curse of dimensionality, bias-variance tradeoff, choice of loss function, architecture design (structural bias), and know about standard coping strategies (dimension Reduction, regularization, cross-validation) 
2) give a coarse overview of the rich landscape of modern ML (supervised / unsupervised / reinforcement learning, 
different modeling attitudes, goals and methods in different subfields of ML) 
3) understand basic algorithmic techniques that is sufficient to allow him/her to practically apply these techniques by programming from scratch or using a high-level toolbox 
4) easily and quickly implement simple (but not necessarily poorly performing) linear, baseline ML pipelines for supervised learning problems 
5) design, implement, run, test and evaluate a more complex, multi-module, nonlinear ML pipeline for supervised learning problems, possibly including unsupervised components
